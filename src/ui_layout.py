import gradio as gr
import matplotlib
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import plotly.express as px

# å¼•ç”¨åŽŸæœ‰çš„æ¨¡çµ„
from src.ai_engine import TutorAI
from src.data_manager import DataManager
from src import config

# å¼•ç”¨æ–°åŠ å…¥çš„æŽ’ç¨‹æ¨¡çµ„ (è«‹ç¢ºä¿ src/scheduler.py å·²å»ºç«‹)
try:
    from src.scheduler import CurriculumScheduler
    SCHEDULER_AVAILABLE = True
except ImportError:
    SCHEDULER_AVAILABLE = False
    print("âš ï¸ Warning: scheduler.py not found. Schedule features will be disabled.")

# è¨­å®šä¸­æ–‡å­—åž‹ (ä¿ç•™åŽŸç‰ˆè¨­å®š)
matplotlib.rcParams["font.sans-serif"] = ["Microsoft JhengHei", "SimHei", "Arial Unicode MS"]
matplotlib.rcParams["axes.unicode_minus"] = False

# åˆå§‹åŒ–å„å€‹ç®¡ç†å™¨
dm = DataManager()
ai = TutorAI()
scheduler = CurriculumScheduler() if SCHEDULER_AVAILABLE else None


def create_ui():
    with gr.Blocks(title="AI Smart Tutor System", theme=gr.themes.Soft()) as app:
        gr.Markdown("# ðŸŽ“ AI Smart Tutor: æ™ºæ…§å®¶æ•™èˆ‡å°ˆæ¡ˆç®¡ç†ç³»çµ±")

        # ç”¨æ–¼è·¨ Tab å…±äº«è³‡æ–™çš„ State
        # é›–ç„¶ DataManager æœƒå­˜æª”ï¼Œä½†ç”¨ State å¯ä»¥è®“æˆ°æƒ…å®¤èˆ‡è³‡æ–™å€åŒæ­¥
        shared_df = gr.State(pd.DataFrame())

        with gr.Tabs():
            
            # =========================================
            # Tab 1: ðŸ†• å…¨ç­æˆ°æƒ…å®¤ (New Feature)
            # =========================================
            with gr.Tab("ðŸ« å…¨ç­æˆ°æƒ…å®¤ (Class Monitor)"):
                gr.Markdown("### ðŸ“Š å­¸ç”Ÿç‹€æ…‹ç¸½è¦½èˆ‡æŽ’ç¨‹å¹²é ")
                with gr.Row():
                    # å·¦å´ï¼šå­¸ç”Ÿç´…ç¶ ç‡ˆåˆ—è¡¨
                    with gr.Column(scale=4):
                        btn_refresh_dashboard = gr.Button("ðŸ”„ æŽƒæå…¨ç­ç‹€æ…‹ (Scan)", variant="primary")
                        student_table = gr.Dataframe(
                            headers=["ID", "Name", "Risk", "Current Topic", "Accuracy"],
                            datatype=["str", "str", "str", "str", "number"],
                            interactive=False,
                            label="é»žæ“Šä»»ä¸€å­¸ç”ŸæŸ¥çœ‹è©³æƒ… ðŸ‘‡"
                        )
                    
                    # å³å´ï¼šç”˜ç‰¹åœ–èˆ‡ä»‹å…¥
                    with gr.Column(scale=6):
                        gr.Markdown("### ðŸ“… AI å­¸ç¿’è·¯å¾‘è¦åŠƒ")
                        selected_student_id = gr.Textbox(label="ç›®å‰é¸å–å­¸ç”Ÿ", interactive=False, value="æœªé¸å–")
                        gantt_chart = gr.Plot(label="å‹•æ…‹ç”˜ç‰¹åœ–")
                        
                        with gr.Group():
                            ai_rationale = gr.Textbox(label="ðŸ¤– AI æŽ’ç¨‹é‚è¼¯ (è§£é‡‹æ€§)", lines=2, interactive=False)
                            btn_optimize = gr.Button("âœ¨ ä¸€éµå„ªåŒ–æ­¤è·¯å¾‘ (Re-schedule)")

            # =========================================
            # Tab 2: ðŸ“Š è³‡æ–™åŒ¯å…¥èˆ‡è¦–è¦ºåŒ– (Original Tab 1)
            # =========================================
            with gr.Tab("ðŸ“Š è³‡æ–™åº«ç®¡ç†"):
                with gr.Row():
                    with gr.Column(scale=1):
                        gr.Markdown("### 1. è³‡æ–™ä¾†æº")
                        btn_load = gr.Button("ðŸ”„ é‡ç½®ç‚ºæ¨¡æ“¬è³‡æ–™", variant="secondary")

                        gr.Markdown("### 2. å¤–éƒ¨åŒ¯å…¥")
                        file_input = gr.File(label="ä¸Šå‚³è³‡æ–™è¡¨", file_count="single")
                        btn_analyze_file = gr.Button("ðŸ“‚ åˆ†æžä¸Šå‚³æª”", variant="primary")
                        import_log = gr.Textbox(label="ç‹€æ…‹", interactive=False)

                    with gr.Column(scale=3):
                        data_display = gr.Dataframe(interactive=False, label="è³‡æ–™é è¦½")

                with gr.Row():
                    plot_scatter = gr.Plot(label="å­¸ç¿’ç‹€æ…‹åˆ†ä½ˆ (å«å›žæ­¸åˆ†æž)")
                    plot_bar = gr.Plot(label="æŽ¨è–¦çµ±è¨ˆ")

            # =========================================
            # Tab 3: ðŸ¤– AI åˆ†æžæ ¸å¿ƒ (Original Tab 2)
            # =========================================
            with gr.Tab("ðŸ§  AI æ ¸å¿ƒè¨“ç·´"):
                gr.Markdown("### ðŸ› ï¸ æ¨¡åž‹è¶…åƒæ•¸èª¿æ•´èˆ‡è¨“ç·´è¦–è¦ºåŒ–")

                with gr.Row():
                    # å·¦å´ï¼šè¶…åƒæ•¸æŽ§åˆ¶é¢æ¿
                    with gr.Column(scale=1):
                        gr.Markdown("#### âš™ï¸ è¶…åƒæ•¸è¨­å®š")

                        hp_lr = gr.Slider(
                            0.01, 0.5, value=0.1, step=0.01,
                            label="Learning Rate (å­¸ç¿’çŽ‡)",
                            info="æŽ§åˆ¶æ¯æ¬¡æ›´æ–°çš„æ­¥é•·ã€‚è¶Šå°è¨“ç·´è¶Šç©©å®šä½†è¶Šæ…¢ï¼Œå»ºè­° 0.01-0.3"
                        )

                        hp_rounds = gr.Slider(
                            10, 500, value=100, step=10,
                            label="Boosting Rounds (è¨“ç·´è¼ªæ•¸)",
                            info="æ¨¡åž‹è¿­ä»£æ¬¡æ•¸ã€‚è¶Šå¤šè¶Šè¤‡é›œï¼Œä½†å¯èƒ½éŽæ“¬åˆï¼Œå»ºè­° 50-200"
                        )

                        hp_depth = gr.Slider(
                            1, 10, value=5, step=1,
                            label="Max Depth (æ¨¹æ·±åº¦)",
                            info="æ±ºç­–æ¨¹çš„æœ€å¤§æ·±åº¦ã€‚è¶Šæ·±æ¨¡åž‹è¶Šè¤‡é›œï¼Œå»ºè­° 3-7"
                        )

                        hp_subsample = gr.Slider(
                            0.5, 1.0, value=1.0, step=0.05,
                            label="Subsample (æ¨£æœ¬æŽ¡æ¨£æ¯”ä¾‹)",
                            info="æ¯æ¬¡è¿­ä»£ä½¿ç”¨çš„æ¨£æœ¬æ¯”ä¾‹ã€‚å°æ–¼ 1.0 å¯é˜²æ­¢éŽæ“¬åˆ"
                        )

                        hp_colsample = gr.Slider(
                            0.5, 1.0, value=1.0, step=0.05,
                            label="Colsample Bytree (ç‰¹å¾µæŽ¡æ¨£æ¯”ä¾‹)",
                            info="æ¯æ£µæ¨¹ä½¿ç”¨çš„ç‰¹å¾µæ¯”ä¾‹ã€‚é™ä½Žå¯å¢žåŠ éš¨æ©Ÿæ€§ï¼Œé˜²æ­¢éŽæ“¬åˆ"
                        )

                        hp_test_size = gr.Slider(
                            0.1, 0.5, value=0.2, step=0.05,
                            label="Validation Split (é©—è­‰é›†æ¯”ä¾‹)",
                            info="ç”¨æ–¼æ¸¬è©¦æ¨¡åž‹çš„è³‡æ–™æ¯”ä¾‹ã€‚å»ºè­° 0.2 (20%)"
                        )

                        gr.Markdown("#### ðŸ”„ äº¤å‰é©—è­‰ (Cross-Validation)")
                        hp_use_cv = gr.Checkbox(
                            label="å•Ÿç”¨äº¤å‰é©—è­‰",
                            value=False,
                            info="ä½¿ç”¨ K-Fold CV è©•ä¼°æ¨¡åž‹ç©©å®šæ€§ï¼ˆæœƒå¢žåŠ è¨“ç·´æ™‚é–“ï¼‰"
                        )

                        hp_cv_folds = gr.Slider(
                            3, 10, value=5, step=1,
                            label="CV Folds (æŠ˜æ•¸)",
                            info="äº¤å‰é©—è­‰çš„æŠ˜æ•¸ï¼Œå»ºè­° 5",
                            visible=False
                        )

                        btn_run_ai_advanced = gr.Button(
                            "ðŸš€ é–‹å§‹è¨“ç·´èˆ‡åˆ†æž",
                            variant="primary",
                            size="lg"
                        )

                        # æŒ‡æ¨™é¡¯ç¤º
                        metric_output = gr.Markdown("### ðŸ“Š è¨“ç·´çµæžœ\nå°šæœªè¨“ç·´")

                    # å³å´ï¼šè¦–è¦ºåŒ–è¼¸å‡º
                    with gr.Column(scale=2):
                        gr.Markdown("#### ðŸ“ˆ è¨“ç·´éŽç¨‹è¦–è¦ºåŒ–")
                        loss_plot = gr.Plot(label="Loss Convergence Curve (æ”¶æ–‚æ›²ç·š)")
                        feat_imp_plot = gr.Plot(label="Feature Importance (ç‰¹å¾µé‡è¦æ€§)")

                # æ¢ä»¶é¡¯ç¤º CV Folds
                hp_use_cv.change(
                    fn=lambda x: gr.update(visible=x),
                    inputs=[hp_use_cv],
                    outputs=[hp_cv_folds]
                )

            # =========================================
            # Tab 4: ðŸ§‘â€ðŸŽ“ å€‹äººèƒ½åŠ›è¨ºæ–· (Original Tab 3)
            # =========================================
            with gr.Tab("ðŸ§‘â€ðŸŽ“ å€‹äººèƒ½åŠ›è¨ºæ–·"):
                gr.Markdown("### è¼¸å…¥å¤šç¶­åº¦æ•¸æ“š")
                with gr.Row():
                    with gr.Column(scale=1):
                        in_accuracy = gr.Slider(0.0, 1.0, value=0.75, label="æ­£ç¢ºçŽ‡ (Accuracy)", step=0.01)
                        in_time = gr.Slider(5.0, 60.0, value=15.0, label="å¹³å‡å®Œæˆæ™‚é–“", step=0.5)
                        in_pace = gr.Slider(0.0, 30.0, value=10.0, label="å­¸ç¿’æ­¥èª¿", step=0.5)
                        in_attend = gr.Slider(0.0, 1.0, value=0.9, label="å‡ºå¸­çŽ‡", step=0.01)
                        in_hw = gr.Slider(0.0, 1.0, value=0.8, label="ä½œæ¥­å®ŒæˆçŽ‡", step=0.01)

                        gr.Markdown("#### éŒ¯èª¤é¡žåž‹")
                        with gr.Row():
                            in_err_read = gr.Number(value=2, label="Reading", precision=0)
                            in_err_vocab = gr.Number(value=1, label="Vocab", precision=0)
                            in_err_logic = gr.Number(value=3, label="Logic", precision=0)
                        in_mean_score = gr.Number(value=80, label="å¹³å‡åˆ†æ•¸", precision=0)

                        btn_predict_user = gr.Button("ðŸ”® é–‹å§‹è¨ºæ–·", variant="primary")

                    with gr.Column(scale=1):
                        output_result = gr.Markdown("### â³ ç­‰å¾…è¼¸å…¥...")
                        output_advice = gr.Markdown("")

        # =========================================
        # Logic Functions (é‚è¼¯å¯¦ä½œå€)
        # =========================================

        # --- 1. åŽŸç‰ˆç¹ªåœ–å‡½æ•¸ (å®Œå…¨ä¿ç•™) ---
        def draw_plots(df: pd.DataFrame):
            # é˜²å‘†ï¼šæª¢æŸ¥å¿…è¦æ¬„ä½
            cols_to_check = [col for col in [config.COL_ACCURACY, config.COL_AVG_TIME] if col in df.columns]
            df = df.dropna(subset=cols_to_check)

            # Scatter Plot (Matplotlib)
            fig_scatter = None
            if not df.empty:
                try:
                    plt.close("all")
                    fig, ax = plt.subplots(figsize=(8, 6))
                    x_col = config.COL_AVG_TIME
                    y_col = config.COL_ACCURACY
                    group_col = config.COL_GROUP if config.COL_GROUP in df.columns else None

                    if group_col:
                        groups = sorted(df[group_col].unique())
                        colors = plt.cm.tab10(np.linspace(0, 1, len(groups)))
                        for idx, group in enumerate(groups):
                            sub_df = df[df[group_col] == group]
                            if len(sub_df) == 0: continue
                            ax.scatter(sub_df[x_col], sub_df[y_col], label=f"Group {group}", color=colors[idx], alpha=0.7, s=80)
                            # å›žæ­¸ç·š
                            if len(sub_df) > 1:
                                try:
                                    slope, intercept = np.polyfit(sub_df[x_col], sub_df[y_col], 1)
                                    x_line = np.linspace(sub_df[x_col].min(), sub_df[x_col].max(), 100)
                                    ax.plot(x_line, slope * x_line + intercept, color=colors[idx], linestyle="--", alpha=0.9)
                                except: pass
                        ax.legend(title="Groups")
                    else:
                        ax.scatter(df[x_col], df[y_col], c="tab:blue", alpha=0.7, s=80)
                    
                    ax.set_xlabel("å¹³å‡å®Œæˆæ™‚é–“ (åˆ†)")
                    ax.set_ylabel("æ­£ç¢ºçŽ‡ (Accuracy)")
                    ax.set_title("å­¸ç”Ÿå­¸ç¿’ç‹€æ…‹åˆ†ä½ˆ", fontname="Microsoft JhengHei", fontsize=14)
                    ax.grid(True, linestyle="--", alpha=0.4)
                    fig.tight_layout()
                    fig_scatter = fig
                except Exception as exc:
                    print(f"Plot Error: {exc}")

            # Bar Plot (Plotly)
            fig_bar = None
            if not df.empty and config.COL_RECOMMENDED_LEVEL in df.columns:
                fig_bar = px.histogram(
                    df,
                    x=config.COL_RECOMMENDED_LEVEL,
                    title="AI æŽ¨è–¦é›£åº¦åˆ†ä½ˆ",
                    text_auto=True,
                    color=config.COL_RECOMMENDED_LEVEL,
                )
            
            return fig_scatter, fig_bar

        # --- 2. åŽŸç‰ˆè³‡æ–™è¼‰å…¥ (å®Œå…¨ä¿ç•™) ---
        def load_default_data():
            df = dm.load_data()
            fig_s, fig_b = draw_plots(df)
            return df, df, fig_s, fig_b, "å·²é‡ç½®ç‚ºæ¨¡æ“¬è³‡æ–™" # æ›´æ–° shared_df

        def process_uploaded_file(file_obj):
            if file_obj is None: return None, None, None, None, "è«‹å…ˆé¸æ“‡æª”æ¡ˆ"
            file_path = file_obj.name if hasattr(file_obj, "name") else file_obj
            df = dm.load_uploaded_file(file_path)
            if df.empty or config.COL_ACCURACY not in df.columns:
                return None, None, None, None, "æª”æ¡ˆæ ¼å¼éŒ¯èª¤"
            
            df, log = ai.run_inference_only(df)
            fig_s, fig_b = draw_plots(df)
            return df, df, fig_s, fig_b, log # æ›´æ–° shared_df

        # --- 3. åŽŸç‰ˆè¨“ç·´æµç¨‹ (å®Œå…¨ä¿ç•™) ---
        def run_training_pipeline():
            df = dm.load_data()
            processed_df, msg = ai.run_analysis_pipeline(df)
            dm.save_results(processed_df)
            fig_s, fig_b = draw_plots(processed_df)
            return processed_df, processed_df, msg, fig_s, fig_b # æ›´æ–° shared_df

        # --- 3b. ðŸ†• é€²éšŽè¨“ç·´æµç¨‹ (æ”¯æ´è¶…åƒæ•¸èˆ‡è¦–è¦ºåŒ–) ---
        def run_training_pipeline_advanced(lr, rounds, depth, subsample, colsample, test_size, use_cv, cv_folds):
            """é€²éšŽè¨“ç·´æµç¨‹ï¼šæ”¯æ´è¶…åƒæ•¸èª¿æ•´èˆ‡è¨“ç·´éŽç¨‹è¦–è¦ºåŒ–"""
            df = dm.load_data()
            if df.empty:
                empty_msg = "### âŒ éŒ¯èª¤\nç„¡è³‡æ–™å¯è¨“ç·´ï¼Œè«‹å…ˆè¼‰å…¥è³‡æ–™"
                return None, None, empty_msg, df

            # å‘¼å«æ›´æ–°å¾Œçš„è¨“ç·´å‡½æ•¸ï¼ˆé–‹å•Ÿ return_detailsï¼‰
            processed_df, training_info = ai.train_prediction_model(
                df,
                test_size=test_size,
                n_estimators=rounds,
                max_depth=depth,
                learning_rate=lr,
                subsample=subsample,
                colsample_bytree=colsample,
                use_cv=use_cv,
                cv_folds=cv_folds,
                return_details=True  # é—œéµï¼šç²å–è¨“ç·´è©³æƒ…
            )

            # å„²å­˜çµæžœ
            dm.save_results(processed_df)

            # === 1. ç¹ªè£½ Loss Convergence Curve ===
            history = training_info.get('history', {})
            if history:
                epochs = len(history['validation_0']['mlogloss'])
                x_axis = list(range(1, epochs + 1))

                fig_loss, ax = plt.subplots(figsize=(8, 5))
                ax.plot(x_axis, history['validation_0']['mlogloss'], label='Train Loss', linewidth=2, marker='o', markersize=4)
                ax.plot(x_axis, history['validation_1']['mlogloss'], label='Val Loss', linestyle='--', linewidth=2, marker='s', markersize=4)
                ax.set_xlabel('Boosting Rounds (Epochs)', fontsize=12)
                ax.set_ylabel('Log Loss', fontsize=12)
                ax.set_title('XGBoost Training Convergence', fontsize=14, fontweight='bold')
                ax.legend(fontsize=11)
                ax.grid(True, alpha=0.3, linestyle='--')
                plt.tight_layout()
            else:
                fig_loss = None

            # === 2. ç¹ªè£½ Feature Importance ===
            feat_imp = training_info.get('feature_importance', {})
            if feat_imp:
                imp_df = pd.DataFrame(list(feat_imp.items()), columns=['Feature', 'Importance'])
                imp_df = imp_df.sort_values(by='Importance', ascending=True)

                fig_imp = px.bar(
                    imp_df,
                    x='Importance',
                    y='Feature',
                    orientation='h',
                    title='AI æ±ºç­–ä¾æ“šï¼šç‰¹å¾µé‡è¦æ€§åˆ†æž',
                    text_auto='.3f',
                    color='Importance',
                    color_continuous_scale='Blues'
                )
                fig_imp.update_layout(height=400, showlegend=False)
            else:
                fig_imp = None

            # === 3. ç”Ÿæˆè¨“ç·´çµæžœæ‘˜è¦ ===
            val_acc = training_info.get('val_accuracy', 0)
            result_text = f"### âœ… è¨“ç·´å®Œæˆï¼\n\n"
            result_text += f"- **é©—è­‰é›†æº–ç¢ºçŽ‡ (Val Accuracy)**: `{val_acc:.2%}`\n"

            # åˆ¤æ–·æ”¶æ–‚ç‹€æ…‹
            if history and len(history['validation_1']['mlogloss']) > 5:
                final_val_loss = history['validation_1']['mlogloss'][-1]
                prev_val_loss = history['validation_1']['mlogloss'][-5]
                if final_val_loss < prev_val_loss:
                    result_text += f"- **æ”¶æ–‚ç‹€æ…‹**: ðŸŸ¢ Loss æŒçºŒä¸‹é™ï¼Œæ¨¡åž‹å¥åº·\n"
                else:
                    result_text += f"- **æ”¶æ–‚ç‹€æ…‹**: ðŸŸ¡ Loss æ³¢å‹•ï¼Œå¯èƒ½å·²æ”¶æ–‚æˆ–éœ€èª¿æ•´åƒæ•¸\n"

            # å¦‚æžœæœ‰ CV çµæžœ
            if 'cv_mean' in training_info:
                cv_mean = training_info['cv_mean']
                cv_std = training_info['cv_std']
                result_text += f"- **äº¤å‰é©—è­‰æº–ç¢ºçŽ‡**: `{cv_mean:.2%} Â± {cv_std:.2%}`\n"
                result_text += f"- **CV åˆ†æ•¸åˆ—è¡¨**: {[f'{s:.2%}' for s in training_info['cv_scores']]}\n"

            result_text += f"\næ¨¡åž‹å·²ä¿å­˜è‡³ `{config.MODEL_FILE_PREDICTION}`"

            return fig_loss, fig_imp, result_text, processed_df

        # --- 4. åŽŸç‰ˆå–®äººé æ¸¬ (å®Œå…¨ä¿ç•™) ---
        def predict_user(acc, time, pace, att, hw, e_read, e_vocab, e_logic, m_score):
            result = str(ai.predict_single(acc, time, pace, att, hw, e_read, e_vocab, e_logic, m_score))
            advice = ""
            if "Hard" in result: advice = "ðŸ’¡ è¡¨ç¾å„ªç•°ï¼Œå»ºè­°æŒ‘æˆ°é€²éšŽèª²ç¨‹ã€‚"
            elif "Easy" in result: advice = "ðŸ’¡ å»ºè­°åŠ å¼·åŸºç¤Žç·´ç¿’ã€‚"
            else: advice = "ðŸ’¡ é€²åº¦ç©©å®šï¼Œé©åˆæ¨™æº–èª²ç¨‹ã€‚"
            return f"# ðŸŽ¯ çµæžœï¼š{result}", advice

        # --- 5. ðŸ†• æ–°å¢žï¼šæˆ°æƒ…å®¤é‚è¼¯ ---
        def refresh_dashboard():
            """æŽƒæè³‡æ–™ï¼Œè¨ˆç®—é¢¨éšªï¼Œæ›´æ–°åˆ—è¡¨"""
            df = dm.load_data()
            # ç¢ºä¿æœ‰ AI é æ¸¬çµæžœ
            df, _ = ai.run_inference_only(df)
            
            # å‘¼å« AI çš„é¢¨éšªè©•ä¼° (éœ€ç¢ºä¿ ai_engine.py æœ‰ batch_evaluate_risk æ–¹æ³•)
            # è‹¥ç„¡ï¼Œå‰‡ä½¿ç”¨ç°¡æ˜“ fallback
            if hasattr(ai, "batch_evaluate_risk"):
                df = ai.batch_evaluate_risk(df)
            else:
                # Fallback logic just in case user didn't update ai_engine.py
                df[config.COL_RISK_LEVEL] = df[config.COL_ACCURACY].apply(lambda x: "ðŸ”´ High Risk" if x < 0.6 else "ðŸŸ¢ On Track")
                df["Current Topic"] = "ä¸€èˆ¬èª²ç¨‹"
            
            # æº–å‚™é¡¯ç¤ºç”¨çš„è¡¨æ ¼ (åªå–é—œéµæ¬„ä½)
            # æª¢æŸ¥æ¬„ä½æ˜¯å¦å­˜åœ¨ï¼Œé¿å… KeyError
            cols = [config.COL_STUDENT_ID, config.COL_NAME, config.COL_RISK_LEVEL, "Current_Topic", config.COL_ACCURACY]
            valid_cols = [c for c in cols if c in df.columns]
            
            display_df = df[valid_cols]
            return df, display_df

        def on_student_select(evt: gr.SelectData, full_df):
            """é»žæ“Šå­¸ç”Ÿå¾Œï¼Œç”ŸæˆæŽ’ç¨‹åœ–"""
            if not SCHEDULER_AVAILABLE:
                return "Scheduler module missing", None, "è«‹æª¢æŸ¥ src/scheduler.py"
            
            if full_df is None or full_df.empty:
                return "ç„¡è³‡æ–™", None, "è«‹å…ˆåŸ·è¡ŒæŽƒæ"
            
            # æ ¹æ“šé»žæ“Šçš„ Row Index æ‰¾åˆ°å­¸ç”Ÿ
            try:
                row_index = evt.index[0]
                student_row = full_df.iloc[row_index]
                s_id = student_row[config.COL_STUDENT_ID]
                s_name = student_row[config.COL_NAME]
                
                # ç”Ÿæˆç”˜ç‰¹åœ–
                df_sched, msg = scheduler.generate_student_schedule(student_row)
                fig = scheduler.plot_gantt(df_sched)
                
                # ç”Ÿæˆè§£é‡‹æ–‡å­—
                risk = student_row.get(config.COL_RISK_LEVEL, "æœªçŸ¥")
                pace = student_row.get(config.COL_LEARNING_PACE, 10)
                reason = f"ã€{risk}ã€‘ å­¸ç”Ÿæ­¥èª¿ä¿‚æ•¸: {pace}ã€‚\nç³»çµ±å·²ä¾æ“šå…¶å¼±é»žé‡æ–°æ¬Šè¡¡èª²ç¨‹å·¥æ™‚ (Resource Leveling)ã€‚"
                
                return f"{s_id} - {s_name}", fig, reason
            except Exception as e:
                return "Error", None, str(e)

        def optimize_schedule_action(s_id_str, full_df):
            """æ¨¡æ“¬è€å¸«ä»‹å…¥å„ªåŒ–"""
            if not SCHEDULER_AVAILABLE: return None, "æ¨¡çµ„ç¼ºå¤±"
            if not s_id_str or "æœªé¸å–" in s_id_str: return None, "è«‹å…ˆé¸æ“‡å­¸ç”Ÿ"
            
            try:
                s_id = s_id_str.split(" - ")[0]
                # æ‰¾åˆ°è©²å­¸ç”Ÿè³‡æ–™
                student_row = full_df[full_df[config.COL_STUDENT_ID] == s_id].iloc[0].copy()
                
                # æ¨¡æ“¬ï¼šå¼·åˆ¶èª¿æ•´åƒæ•¸
                student_row[config.COL_LEARNING_PACE] = float(student_row[config.COL_LEARNING_PACE]) * 1.5
                
                df_sched, msg = scheduler.generate_student_schedule(student_row)
                fig = scheduler.plot_gantt(df_sched)
                return fig, f"âœ… å·²å¼·åˆ¶èª¿æ•´è©²ç”Ÿæ¬Šé‡ (Pace x 1.5) ä¸¦é‡æ–°æŽ’ç¨‹ã€‚\n{msg}"
            except Exception as e:
                return None, str(e)

        # =========================================
        # Event Bindings (äº‹ä»¶ç¶å®š)
        # =========================================
        
        # Tab 1: æˆ°æƒ…å®¤äº‹ä»¶
        btn_refresh_dashboard.click(refresh_dashboard, outputs=[shared_df, student_table])
        student_table.select(on_student_select, inputs=[shared_df], outputs=[selected_student_id, gantt_chart, ai_rationale])
        btn_optimize.click(optimize_schedule_action, inputs=[selected_student_id, shared_df], outputs=[gantt_chart, ai_rationale])

        # Tab 2: è³‡æ–™ç®¡ç†äº‹ä»¶ (æ³¨æ„ï¼šé€™è£¡åŒæ™‚æ›´æ–° shared_df)
        btn_load.click(load_default_data, outputs=[shared_df, data_display, plot_scatter, plot_bar, import_log])
        btn_analyze_file.click(process_uploaded_file, inputs=[file_input], outputs=[shared_df, data_display, plot_scatter, plot_bar, import_log])

        # Tab 3: è¨“ç·´äº‹ä»¶ (æ–°ç‰ˆé€²éšŽè¨“ç·´)
        btn_run_ai_advanced.click(
            run_training_pipeline_advanced,
            inputs=[hp_lr, hp_rounds, hp_depth, hp_subsample, hp_colsample, hp_test_size, hp_use_cv, hp_cv_folds],
            outputs=[loss_plot, feat_imp_plot, metric_output, shared_df]
        )

        # Tab 4: é æ¸¬äº‹ä»¶
        btn_predict_user.click(
            fn=predict_user,
            inputs=[in_accuracy, in_time, in_pace, in_attend, in_hw, in_err_read, in_err_vocab, in_err_logic, in_mean_score],
            outputs=[output_result, output_advice]
        )

        # åˆå§‹è¼‰å…¥
        app.load(fn=load_default_data, outputs=[shared_df, data_display, plot_scatter, plot_bar, import_log])

    return app